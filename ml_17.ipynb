{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 処理パタン\n",
    "\n",
    "処理パタンは決まっていて、それを呼び出すだけ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    print(f'device count: {torch.cuda.device_count()}')\n",
    "    print(f'device name: {torch.cuda.get_device_name()}')\n",
    "    print(f'device capability: {torch.cuda.get_device_capability()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### １階テンソル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5),\n",
    "    transforms.Lambda(lambda x: x.view(-1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正規化のみ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    '''\n",
    "    隠れ層が１層のNN\n",
    "    '''\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(n_input, n_hidden)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.l2 = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_parameters(net):\n",
    "    for parameter in net.named_parameters():\n",
    "        print(parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss_for_computational_graph(loader, device, net, criterion):\n",
    "    # データローダから最初の１セット取得（計算グラフ作成のため）\n",
    "    for images, labels in loader:\n",
    "        break\n",
    "    # デバイス（GPU/CPU割当）\n",
    "    inputs = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    # 予測計算\n",
    "    outputs = net(inputs)\n",
    "    # 損失計算\n",
    "    loss = criterion(outputs, labels)\n",
    "    # 計算グラフの表示\n",
    "    make_dot(loss, params=dict(net.named_parameters()))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習・追加学習用関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.zeros((0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history):\n",
    "    base_epochs = len(history)\n",
    "\n",
    "    for epoch in range(base_epochs, num_epochs + base_epochs):\n",
    "        # 1エポックあたりの正解数（精度計算用）\n",
    "        n_train_acc, n_val_acc = 0, 0\n",
    "        # 1エポックあたりの累積損失（平均化前）\n",
    "        train_loss, val_loss = 0, 0\n",
    "        # 1エポックあたりのデータ数\n",
    "        n_train, n_test = 0, 0\n",
    "\n",
    "        ##### 訓練 #####\n",
    "        net.train() # ドロップアウト関数nn.DropoutやBN関数nn.BatchNorm2dに訓練中であることを伝える関数\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            train_batch_size = len(labels)\n",
    "            n_train += train_batch_size\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = torch.max(outputs, 1)[1]\n",
    "            train_acc += (predicted == labels).sum().item()\n",
    "            train_loss += loss.item() * train_batch_size\n",
    "\n",
    "        train_acc /= n_train\n",
    "        train_loss /= n_train\n",
    "\n",
    "        ##### 予測 #####\n",
    "        net.eval() # ドロップアウト関数nn.DropoutやBN関数nn.BatchNorm2dに予測中であることを伝える関数\n",
    "\n",
    "        for inputs_test, labels_test in test_loader:\n",
    "            test_batch_size = len(labels_test)\n",
    "            n_test += test_batch_size\n",
    "\n",
    "            inputs_test = inputs_test.to(device)\n",
    "            labels_test = labels_test.to(device)\n",
    "\n",
    "            outputs_test = net(inputs_test)\n",
    "            loss_test = criterion(outputs_test, labels_test)\n",
    "\n",
    "            predict_test = torch.max(outputs_test, 1)[1]\n",
    "            val_acc += (predict_test == labels_test).sum().item()\n",
    "            val_loss += loss_test.item() * test_batch_size\n",
    "\n",
    "        val_acc /= n_test\n",
    "        val_loss /= n_test\n",
    "\n",
    "        item = np.array([epoch, train_loss, train_acc, val_loss, val_acc])\n",
    "        history = np.vstack((history, item))\n",
    "        if epoch % (num_epochs / 100) == 0:\n",
    "            print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習ログ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_history(history):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_history(history):\n",
    "    plt.plot(history[:, 0], history[:, 1], label='train loss')\n",
    "    plt.plot(history[:, 0], history[:, 3], label='val loss')\n",
    "    plt.legend()\n",
    "    plt.title('Learning Curve wrt Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_history(history):\n",
    "    plt.plot(history[:, 0], history[:, 2], label='train acc')\n",
    "    plt.plot(history[:, 0], history[:, 4], label='val acc')\n",
    "    plt.legend()\n",
    "    plt.title('Learning Curve wrt Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測結果表示（画像分析結果）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 乱数を固定する（結果の再現性を担保するため）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_seed(seed=123):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # GPUで結果がdeterministicになるように\n",
    "    torch.use_deterministic_algorithms = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
